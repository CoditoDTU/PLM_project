{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/miniforge3/envs/proteusAI/lib/python3.8/site-packages/proteusAI/ml_tools/esm_tools/esm_tools.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  alphabet = torch.load(os.path.join(Path(__file__).parent, \"alphabet.pt\"))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pymongo import MongoClient\n",
    "from functools import reduce\n",
    "from collections import defaultdict\n",
    "import proteusAI as pai\n",
    "import os\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "import esm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions required(made by johnny):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esm_compute(seqs: list, names: list=None, model: Union[str, torch.nn.Module]=\"esm1v\", rep_layer: int=33, device=None):\n",
    "    \"\"\"\n",
    "    Compute the of esm_tools models for a list of sequences.\n",
    " \n",
    "    Args:\n",
    "        seqs (list): protein sequences either as str or biotite.sequence.ProteinSequence.\n",
    "        names (list, default None): list of names/labels for protein sequences.\n",
    "            If None sequences will be named seq1, seq2, ...\n",
    "        model (str, torch.nn.Module): choose either esm2, esm1v or a pretrained model object.\n",
    "        rep_layer (int): choose representation layer. Default 33.\n",
    "        device (str): Choose hardware for computation. Default 'None' for autoselection\n",
    "                          other options are 'cpu' and 'cuda'.\n",
    " \n",
    "    Returns: representations (list) of sequence representation, batch lens and batch labels\n",
    " \n",
    "    Example:\n",
    "        seqs = [\"AGAVCTGAKLI\", \"AGHRFLIKLKI\"]\n",
    "        results, batch_lens, batch_labels = esm_compute(seqs)\n",
    "    \"\"\"\n",
    "    # detect device\n",
    "    if device == None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    else:\n",
    "        device = torch.device(device)\n",
    " \n",
    "    # on M1 if mps available\n",
    "    #if device == torch.device(type='cpu'):\n",
    "    #    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    " \n",
    "    # load model\n",
    "    if isinstance(model, str):\n",
    "        if model == \"esm2\":\n",
    "            model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "        elif model == \"esm1v\":\n",
    "            model, alphabet = esm.pretrained.esm1v_t33_650M_UR90S()\n",
    "        else:\n",
    "            raise ValueError(f\"{model} is not a valid model\")\n",
    "    elif isinstance(model, torch.nn.Module):\n",
    "        alphabet = torch.load(os.path.join(Path(__file__).parent, \"alphabet.pt\"))\n",
    "    else:\n",
    "        raise TypeError(\"Model should be either a string or a torch.nn.Module object\")\n",
    " \n",
    " \n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    " \n",
    "    if names == None:\n",
    "        names = names = [f'seq{i}' for i in range(len(seqs))]\n",
    " \n",
    "    data = list(zip(names, seqs))\n",
    " \n",
    "    # check datatype of sequences - str or biotite\n",
    "    if all(isinstance(x[0], str) and isinstance(x[1], str) for x in data):\n",
    "        pass  # all elements are strings\n",
    "    else:\n",
    "        data = [(x[0], str(x[1])) for x in data]\n",
    " \n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "    batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    " \n",
    "    # Extract per-residue representations (on CPU)\n",
    "    with torch.no_grad():\n",
    "        results = model(batch_tokens.to(device), repr_layers=[rep_layer], return_contacts=True)\n",
    " \n",
    "    return results, batch_lens, batch_labels, alphabet\n",
    "\n",
    "# Get representations\n",
    "def get_seq_rep(results, batch_lens):\n",
    "    \"\"\"\n",
    "    Get sequence representations from esm_compute\n",
    "    \"\"\"\n",
    "    token_representations = results[\"representations\"][33]\n",
    " \n",
    "    # Generate per-sequence representations via averaging\n",
    "    sequence_representations = []\n",
    "    for i, tokens_len in enumerate(batch_lens):\n",
    "        sequence_representations.append(token_representations[i, 1: tokens_len - 1].mean(0))\n",
    " \n",
    "    return sequence_representations\n",
    " \n",
    "def get_logits(results):\n",
    "    \"\"\"\n",
    "    Get logits from esm_compute\n",
    "    \"\"\"\n",
    "    logits = results[\"logits\"]\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader for with mongo DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connects to the internal db and reads the example within it.\n",
    "def connect_db():\n",
    "    # Connect to MongoDB with connection string\n",
    "    string_path = \"mongodb://127.0.0.1:27017/?directConnection=true&serverSelectionTimeoutMS=2000&appName=mongosh+2.3.3\"\n",
    "    \n",
    "    client = MongoClient(string_path)\n",
    "\n",
    "    # Create db\n",
    "    db = client['proteins']\n",
    "\n",
    "    # Access collection\n",
    "    collection = db['uniref_test']\n",
    "\n",
    "    return client, db, collection\n",
    "\n",
    "# Selects correct data from the db retrieved data:\n",
    "def get_taxon_sequence_data(collection):\n",
    "\n",
    "    # Define the query filter to exclude documents where sequence.length > 1024\n",
    "    query = {\n",
    "        \"sequence.length\": {\"$lte\": 1024}\n",
    "    }\n",
    "    projection = {\n",
    "    \"primaryAccession\": 1,    \n",
    "    \"organism.taxonId\": 1,   # Include taxonId from the organism field\n",
    "    \"sequence.value\": 1,      # Include value from the sequence field\n",
    "    \"sequence.length\": 1      # Include length from the sequence field\n",
    "    }\n",
    "    documents =  collection.find(query, projection)\n",
    "\n",
    "    minimal_documents = [] # Initialize new empty dictionary\n",
    "\n",
    "    for doc in documents:\n",
    "    # Create a new dictionary with only the desired properties\n",
    "        new_obj = {\n",
    "            \"primaryAccession\": doc.get(\"primaryAccession\",{}),\n",
    "            \"taxonId\": doc.get(\"organism\", {}).get(\"taxonId\"),\n",
    "            \"value\": doc.get(\"sequence\", {}).get(\"value\"),\n",
    "            \"length\": doc.get(\"sequence\", {}).get(\"length\")\n",
    "        }\n",
    "        minimal_documents.append(new_obj)\n",
    "\n",
    "\n",
    "    return minimal_documents\n",
    "\n",
    "\n",
    "def get_taxon_sequence_data(collection):\n",
    "\n",
    "    documents = collection['results']\n",
    "\n",
    "    minimal_documents = [] # Initialize new empty dictionary\n",
    "\n",
    "    for doc in documents:\n",
    "    # Create a new dictionary with only the desired properties\n",
    "        new_obj = {\n",
    "            \"primaryAccession\": doc.get(\"primaryAccession\",{}),\n",
    "            \"taxonId\": doc.get(\"organism\", {}).get(\"taxonId\"),\n",
    "            \"value\": doc.get(\"sequence\", {}).get(\"value\"),\n",
    "            \"length\": doc.get(\"sequence\", {}).get(\"length\")\n",
    "        }\n",
    "        minimal_documents.append(new_obj)\n",
    "\n",
    "\n",
    "    return minimal_documents\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client, db, collection = connect_db()\n",
    "\n",
    "data = get_taxon_sequence_data(collection=collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'primaryAccession': 'O13437',\n",
       " 'taxonId': 5477,\n",
       " 'value': 'MKIVLVLYDAGKHAADEEKLYGCTENKLGIANWLKDQGHELITTSDKEGETSELDKHIPDADIIITTPFHPAYITKERLDKAKNLKLVVVAGVGSDHIDLDYINQTGKKISVLEVTGSNVVSVAEHVVMTMLVLVRNFVPAHEQIINHDWEVAAIAKDAYDIEGKTIATIGAGRIGYRVLERLLPFNPKELLYYDYQALPKEAEEKVGARRVENIEELVAQADIVTVNAPLHAGTKGLINKELLSKFKKGAWLVNTARGAICVAEDVAAALESGQLRGYGGDVWFPQPAPKDHPWRDMRNKYGAGNAMTPHYSGTTLDAQTRYAEGTKNILESFFTGKFDYRPQDIILLNGEYVTKAYGKHDKK',\n",
       " 'length': 364}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "\n",
    "        self.data = data\n",
    "        #data[' length'] = data[' length'].str.replace(r'\\^\\^<.*?>', '', regex=True).astype(int)\n",
    "        #data[' taxon'] = data[' taxon'].str.extract(r'h.*/(\\d+)/?$')[0].astype(int)\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(index, list):\n",
    "            return [self.data[i] for i in index]\n",
    "        \n",
    "        item = self.data[index]\n",
    "\n",
    "        # Extract relevant fields\n",
    "        sequence = item['value']  # The protein sequence\n",
    "        length = item['length']   # Length of the sequence\n",
    "        taxon_id = item['taxonId']  # Taxon ID\n",
    "        primary_accession = item['primaryAccession']  # Primary accession\n",
    "\n",
    "        return {\n",
    "            'sequence': sequence,  # Return sequence as a string (you could modify this later)\n",
    "            'length': length,\n",
    "            'taxon_id': taxon_id,\n",
    "            'primary_accession': primary_accession\n",
    "        }\n",
    "\n",
    "## Dummy sampler\n",
    "class CustomSampler(Sampler):\n",
    "\n",
    "    def __init__(self, data_source : Dataset, shuffle = True):\n",
    "\n",
    "        self.data_source = data_source\n",
    "        self.indices = list(range(len(data_source)))\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        \n",
    "        if self.shuffle:\n",
    "                random.shuffle(self.indices)  # Shuffle the indices if needed\n",
    "            \n",
    "        # Return the indices one by one (you could also apply custom logic here)\n",
    "        for idx in self.indices:\n",
    "            yield idx\n",
    "            \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the number of items in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data_source)\n",
    "\n",
    "\n",
    "class TaxonIdSampler(Sampler):\n",
    "    def __init__(self, dataset: Dataset, batch_size, length_bin_size=5, shuffle=True):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.length_bin_size = length_bin_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # Group sample indices by taxonId\n",
    "        self.taxon_length_bins = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "        for idx, sample in enumerate(dataset):\n",
    "            taxon_id = sample['taxon_id']\n",
    "            sequence_length = sample['length']\n",
    "            length_bin = (sequence_length // length_bin_size) * length_bin_size  # integer division to know in which bucket the sequence is\n",
    "\n",
    "            # Ensure that length_bin is properly initialized\n",
    "            self.taxon_length_bins[taxon_id][length_bin].append(idx)\n",
    "\n",
    "        '''\n",
    "        structure of self.taxon_length_bins:\n",
    "\n",
    "        {\n",
    "            taxon_id_1: {\n",
    "                length_bin_1: [sample_idx_1, sample_idx_2, ...],\n",
    "                length_bin_2: [sample_idx_3, sample_idx_4, ...],\n",
    "                ...\n",
    "            },\n",
    "            taxon_id_2: {\n",
    "                length_bin_3: [sample_idx_5, sample_idx_6, ...],\n",
    "                ...\n",
    "            },\n",
    "        }\n",
    "        '''\n",
    "        \n",
    "        # Prepare batches based on taxon groups\n",
    "        self.batches = []\n",
    "\n",
    "        for taxon, length_bins in self.taxon_length_bins.items():\n",
    "            for length_bin, indices in length_bins.items():\n",
    "                if self.shuffle:\n",
    "                    random.shuffle(indices)  # Shuffle the indices if needed\n",
    "                for i in range(0, len(indices), batch_size):\n",
    "                    self.batches.append(indices[i:i + batch_size])\n",
    "\n",
    "        # Shuffle the batches if needed\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.batches)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.batches:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batches)\n",
    "\n",
    "def dict_collate_fn(batch):\n",
    "    # Return the batch as-is (a list of dictionaries)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetdb = ProteinDataset(data)\n",
    "#samplerdb = CustomSampler(datasetdb, shuffle=True)\n",
    "samplerdb = TaxonIdSampler(datasetdb, batch_size = 5 , shuffle=True)\n",
    "#dataloaderdb = DataLoader(dataset = datasetdb ,batch_size = 5, sampler = samplerdb)\n",
    "dataloaderdb = DataLoader(dataset = datasetdb , sampler = samplerdb, collate_fn=dict_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'primaryAccession': 'A6ZN46', 'taxonId': 307796, 'value': 'MSKGKVLLVLYEGGKHAEEQEKLLGCIENELGIRNFIEEQGYELVTTIDKDPEPTSTVDRELKDAEIVITTPFFPAYISRNRIAEAPNLKLCVTAGVGSDHVDLEAANERKITVTEVTGSNVVSVAEHVMATILVLIRNYNGGHQQAINGEWDIAGVAKNEYDLEDKIISTVGAGRIGYRVLERLVAFNPKKLLYYDYQELPAEAINRLNEASKLFNGRGDIVQRVEKLEDMVAQSDVVTINCPLHKDSRGLFNKKLISHMKDGAYLVNTARGAICVAEDVAEAVKSGKLAGYGGDVWDKQPAPKDHPWRTMDNKDHVGNAMTVHISGTSLDAQKRYAQGVKNILNSYFSKKFDYRPQDIIVQNGSYATRAYGQKK', 'length': 376}]]\n",
      "[[{'primaryAccession': 'P33160', 'taxonId': 33067, 'value': 'MAKVLCVLYDDPVDGYPKTYARDDLPKIDHYPGGQTLPTPKAIDFTPGQLLGSVSGELGLRKYLESNGHTLVVTSDKDGPDSVFERELVDADVVISQPFWPAYLTPERIAKAKNLKLALTAGIGSDHVDLQSAIDRNVTVAEVTYCNSISVAEHVVMMILSLVRNYLPSHEWARKGGWNIADCVSHAYDLEAMHVGTVAAGRIGLAVLRRLAPFDVHLHYTDRHRLPESVEKELNLTWHATREDMYPVCDVVTLNCPLHPETEHMINDETLKLFKRGAYIVNTARGKLCDRDAVARALESGRLAGYAGDVWFPQPAPKDHPWRTMPYNGMTPHISGTTLTAQARYAAGTREILECFFEGRPIRDEYLIVQGGALAGTGAHSYSKGNATGGSEEAAKFKKAV', 'length': 401}]]\n",
      "[[{'primaryAccession': 'G0SGU4', 'taxonId': 759272, 'value': 'MVKVLAVLYDGGEHAKQVPGLLGTTENELGLRKWLEDQGHTLVTTSDKDREGSTFDRELEDAEIIITTPFHPGYLTAERLARAKKLKLAVTAGIGSDHVDLDAANKTNGGITVAEVTGSNVVSVAEHVVMTILVLVRNFVPAHEQIEAGRWDVAEVAKDEYDLEGKVVGTVGVGRIGERVLRRLKGFDCKELLYYDYQPLSPEKEKEIGCRRVENLEEMLAQCDVVTINCPLHESTRGLFNKDLISKMKRGSWLVNTARGAIVVKEDVAEALRTGHLRGYGGDVWFPQPAPADHVLRTAKNPFGGGNAMVPHMSGTSLDAQKRYAEGVKRILDSYLSGRFDYRPEDLIVHQGKYATRAYGQREDVKIPGQ', 'length': 370}]]\n",
      "[[{'primaryAccession': 'C8ZHD6', 'taxonId': 643680, 'value': 'MSKGKVLLVLYEGGKHAEEQEKLLGCIENELGIRNFIEEQGYELVTTIDKDPEPTSTVDRELKDAEIVITTPFFPAYISRNRIAEAPNLKLCVTAGVGSDHVDLEAANERKITVTEVTGSNVVSVAEHVMATILVLIRNYNGGHQQAINGEWDIAGVAKNEYDLEDKIISTVGAGRIGYRVLERLVAFNPKKLLYYDYQELPAEAINRLNEASKLFNGRGDIVQRVEKLEDMVAQSDVVTINCPLHKDSRGLFNKKLISHMKDGAYLVNTARGAICVAEDVAEAVKSGKLAGYGGDVWDKQPAPKDHPWRTMDNKDHVGNAMTVHISGTSLDAQKRYAQGVKNILNSYFSKKFDYRPQDIIVQNGSYATRAYGQKK', 'length': 376}]]\n",
      "[[{'primaryAccession': 'Q07511', 'taxonId': 4113, 'value': 'MAMSRVASTAARAITSPSSLVFTRELQASPGPKKIVGVFYKANEYAEMNPNFLGCAENALGIREWLESKGHQYIVTPDKEGPDCELEKHIPDLHVLISTPFHPAYVTAERIKKAKNLQLLLTAGIGSDHVDLKAAAAAGLTVAEVTGSNTVSVAEDELMRILILVRNFLPGHHQVINGEWNVAAIAHRAYDLEGKTVGTVGAGRIGRLLLQRLKPFNCNLLYHDRLKMDSELENQIGAKFEEDLDKMLSKCDIVVINTPLTEKTKGMFDKERIAKLKKGVLIVNNARGAIMDTQAVVDACNSGHIAGYSGDVWYPQPAPKDHPWRYMPNQAMTPHISGTTIDAQLRYAAGTKDMLDRYFKGEDFPAENYIVKDGELAPQYR', 'length': 381}]]\n",
      "[[{'primaryAccession': 'P46415', 'taxonId': 7227, 'value': 'MSATEGKVITCKAAVAWEAKKPLVIEDIEVAPPKAHEVRIKITATGVCHTDAFTLSGADPEGLFPVVLGHEGAGIVESVGEGVTNFKAGDHVIALYIPQCNECKFCKSGKTNLCQKIRLTQGAGVMPEGTSRLSCKGQQLFHFMGTSTFAEYTVVADISLTKINEKAPLEKVCLLGCGISTGYGAALNTAKVEAGSTCAVWGLGAVGLAVGLGCKKAGAGKIYGIDINPDKFELAKKFGFTDFVNPKDVADKGSIQNYLIDLTDGGFDYTFECIGNVNTMRSALEATHKGWGTSVVIGVAGAGQEISTRPFQLVVGRVWKGSAFGGWRSVSDVPKLVEDYLKKDLLVDEFITHELPLSQINEAFDLMHKGESIRSIIKY', 'length': 379}]]\n",
      "[[{'primaryAccession': 'Q9S7E4', 'taxonId': 3702, 'value': 'MAMRQAAKATIRACSSSSSSGYFARRQFNASSGDSKKIVGVFYKANEYATKNPNFLGCVENALGIRDWLESQGHQYIVTDDKEGPDCELEKHIPDLHVLISTPFHPAYVTAERIKKAKNLKLLLTAGIGSDHIDLQAAAAAGLTVAEVTGSNVVSVAEDELMRILILMRNFVPGYNQVVKGEWNVAGIAYRAYDLEGKTIGTVGAGRIGKLLLQRLKPFGCNLLYHDRLQMAPELEKETGAKFVEDLNEMLPKCDVIVINMPLTEKTRGMFNKELIGKLKKGVLIVNNARGAIMERQAVVDAVESGHIGGYSGDVWDPQPAPKDHPWRYMPNQAMTPHTSGTTIDAQLRYAAGTKDMLERYFKGEDFPTENYIVKDGELAPQYR', 'length': 384}]]\n",
      "[[{'primaryAccession': 'Q17335', 'taxonId': 6239, 'value': 'MSSTAGQVINCKAAVAWSAKAPLSIETIQVAPPKAHEVRVKILYTAVCHTDAYTLDGHDPEGLFPVVLGHEGSGIVESVGEGVTGFAPGDHVVPLYVPQCKECEYCKNPKTNLCQKIRISQGNGFMPDGSSRFTCNGKQLFHFMGCSTFSEYTVVADISLCKVNPEAPLEKVSLLGCGISTGYGAVLNTCKVEEGSTVAVWGLGAVGLAVIMGAKAAGAKKIVGIDLIESKFESAKFFGATECINPKSVELPEGKSFQAWLVEQFDGGFDYTFECIGNVHTMRQALEAAHKGWGVSCIIGVAGAGQEIATRPFQLVTGRTWKGTAFGGWKSVESVPRLVDDYMNKKLLIDEFITHRWNIDDINTAFDVLHKGESLRSVLAFEKI', 'length': 384}]]\n",
      "[[{'primaryAccession': 'P80572', 'taxonId': 3888, 'value': 'ATQGQVITCKAAVAWEPNKPLTIEDVEVAPPQANEVRIQILFTALCHTDAYTLGGKDPEGLFPCILGHEAAGIVESVGEGVTDVKPGDHVIPSYQAECGECKFCKSPKTNLCGKVRAATGVGVMMADRKSRFSVKGKPIYHFMGTSTFSQYTVVHDVSVAKIHPDAPLDKVCLLGCGVPTGLGAVWNTAKVEPGSIVAIFGLGTVGLAVAEGAKSAGASRIIGIDIDSNKYDTAKNFGVTEFINPKDHEKPIQQVIIDLTDGGVDYSFECLGNVSVMRSALECCHKGWGTSVIVGVAASGQEISTRPFQLVTGRVWKGTAFGGFKSRSQVPWLVEKYLKKEIKVDEYITHNLTLLEINKAFDLLHEGQCLRCVLAVHD', 'length': 378}]]\n",
      "[[{'primaryAccession': 'P11766', 'taxonId': 9606, 'value': 'MANEVIKCKAAVAWEAGKPLSIEEIEVAPPKAHEVRIKIIATAVCHTDAYTLSGADPEGCFPVILGHEGAGIVESVGEGVTKLKAGDTVIPLYIPQCGECKFCLNPKTNLCQKIRVTQGKGLMPDGTSRFTCKGKTILHYMGTSTFSEYTVVADISVAKIDPLAPLDKVCLLGCGISTGYGAAVNTAKLEPGSVCAVFGLGGVGLAVIMGCKVAGASRIIGVDINKDKFARAKEFGATECINPQDFSKPIQEVLIEMTDGGVDYSFECIGNVKVMRAALEACHKGWGVSVVVGVAASGEEIATRPFQLVTGRTWKGTAFGGWKSVESVPKLVSEYMSKKIKVDEFVTHNLSFDEINKAFELMHSGKSIRTVVKI', 'length': 374}]]\n",
      "[[{'primaryAccession': 'Q3ZC42', 'taxonId': 9913, 'value': 'MANQVIKCKAAVAWEAGKPLSIEEVEVAPPKAHEVRIKIIATAVCHTDAYTLSGADPEGNYPVILGHEGAGIVESVGEGVTKLKAGDTVIPLYIPQCGECKFCLNPKTNLCQKIRVTQGKGLMPDGTSRFTCKGKTILHYMGTSTFSEYTVVADISVAKIDPLAPLDKVCLLGCGISTGYGAALNAAKVEPGSTCAVFGLGGVGLAVIMGCKMAGAARIIGVDINKDKFARAKEFGASECINPQDFSKPIQEVLIEMTDGGVDYSFECIGNVKVMRAALEACHKGWGISVVVGVAASGEEIATRPFQLVTGRTWKGTAFGGWKSVESVPKLVSEYMSKKIKVDEFVTHSLPFDQINEAFDLMHAGKSIRTVVKL', 'length': 374}]]\n",
      "[[{'primaryAccession': 'P25437', 'taxonId': 83333, 'value': 'MKSRAAVAFAPGKPLEIVEIDVAPPKKGEVLIKVTHTGVCHTDAFTLSGDDPEGVFPVVLGHEGAGVVVEVGEGVTSVKPGDHVIPLYTAECGECEFCRSGKTNLCVAVRETQGKGLMPDGTTRFSYNGQPLYHYMGCSTFSEYTVVAEVSLAKINPEANHEHVCLLGCGVTTGIGAVHNTAKVQPGDSVAVFGLGAIGLAVVQGARQAKAGRIIAIDTNPKKFDLARRFGATDCINPNDYDKPIKDVLLDINKWGIDHTFECIGNVNVMRAALESAHRGWGQSVIIGVAVAGQEISTRPFQLVTGRVWKGSAFGGVKGRSQLPGMVEDAMKGDIDLEPFVTHTMSLDEINDAFDLMHEGKSIRTVIRY', 'length': 369}]]\n",
      "[[{'primaryAccession': 'Q07103', 'taxonId': 367110, 'value': 'MVKVLAVLYDGGKHGEEVPELLGTIQNELGLRKWLEDQGHTLVTTCDKDGENSTFDKELEDAEIIITTPFHPGYLTAERLARAKKLKLAVTAGIGSDHVDLNAANKTNGGITVAEVTGSNVVSVAEHVLMTILVLVRNFVPAHEQIQEGRWDVAEAAKNEFDLEGKVVGTVGVGRIGERVLRRLKPFDCKELLYYDYQPLSAEKEAEIGCRRVADLEEMLAQCDVVTINCPLHEKTQGLFNKELISKMKKGSWLVNTARGAIVVKEDVAEALKSGHLRGYGGDVWFPQPAPQDHPLRYAKNPFGGGNAMVPHMSGTSLDAQKRYAAGTKAIIESYLSGKHDYRPEDLIVYGGDYATKSYGERERAKAAAAAAKSA', 'length': 375}]]\n",
      "[[{'primaryAccession': 'P33677', 'taxonId': 870730, 'value': 'MKVVLVLYDAGKHAQDEERLYGCTENALGIRDWLEKQGHDVVVTSDKEGQNSVLEKNISDADVIISTPFHPAYITKERIDKAKKLKLLVVAGVGSDHIDLDYINQSGRDISVLEVTGSNVVSVAEHVVMTMLVLVRNFVPAHEQIISGGWNVAEIAKDSFDIEGKVIATIGAGRIGYRVLERLVAFNPKELLYYDYQSLSKEAEEKVGARRVHDIKELVAQADIVTINCPLHAGSKGLVNAELLKHFKKGAWLVNTARGAICVAEDVAAAVKSGQLRGYGGDVWFPQPAPKDHPWRSMANKYGAGNAMTPHYSGSVIDAQVRYAQGTKNILESFFTQKFDYRPQDIILLNGKYKTKSYGADK', 'length': 362}]]\n",
      "[[{'primaryAccession': 'Q08911', 'taxonId': 559292, 'value': 'MSKGKVLLVLYEGGKHAEEQEKLLGCIENELGIRNFIEEQGYELVTTIDKDPEPTSTVDRELKDAEIVITTPFFPAYISRNRIAEAPNLKLCVTAGVGSDHVDLEAANERKITVTEVTGSNVVSVAEHVMATILVLIRNYNGGHQQAINGEWDIAGVAKNEYDLEDKIISTVGAGRIGYRVLERLVAFNPKKLLYYDYQELPAEAINRLNEASKLFNGRGDIVQRVEKLEDMVAQSDVVTINCPLHKDSRGLFNKKLISHMKDGAYLVNTARGAICVAEDVAEAVKSGKLAGYGGDVWDKQPAPKDHPWRTMDNKDHVGNAMTVHISGTSLDAQKRYAQGVKNILNSYFSKKFDYRPQDIIVQNGSYATRAYGQKK', 'length': 376}]]\n",
      "[[{'primaryAccession': 'O13437', 'taxonId': 5477, 'value': 'MKIVLVLYDAGKHAADEEKLYGCTENKLGIANWLKDQGHELITTSDKEGETSELDKHIPDADIIITTPFHPAYITKERLDKAKNLKLVVVAGVGSDHIDLDYINQTGKKISVLEVTGSNVVSVAEHVVMTMLVLVRNFVPAHEQIINHDWEVAAIAKDAYDIEGKTIATIGAGRIGYRVLERLLPFNPKELLYYDYQALPKEAEEKVGARRVENIEELVAQADIVTVNAPLHAGTKGLINKELLSKFKKGAWLVNTARGAICVAEDVAAALESGQLRGYGGDVWFPQPAPKDHPWRDMRNKYGAGNAMTPHYSGTTLDAQTRYAEGTKNILESFFTGKFDYRPQDIILLNGEYVTKAYGKHDKK', 'length': 364}]]\n",
      "[[{'primaryAccession': 'Q67U69', 'taxonId': 39947, 'value': 'MAMWRAPSAAGQLLGRALASTAAQTSAGSKKVVGVFYKGGEYADKNPNFVGCVDSALGIRGWLESKGHRYIVTDDKEGINCELEKHIEDAHVLITTPFHPAYITAERIKKAKNLELLLTAGVGSDHIDLPAAAAAGLTVAEITGSNTVSVAEDQLMRILLLLRNFLPGHHQIVNGEWNVAGIAHRTYDLEGKTVGTVGAGRIGRLLLQRLKPFNCNLMYHDRVKIDPELEKEIGAKYEEDLDAMLPKCDVVVINMPLTEKTRGMFNKERIAKMKKGVTIVNNARGAIMDTQAVADACASGHVAGYGGDVWFPQPAPKDHPWRYMPNHAMTPHCSGTTIDGQLRYAAGVKDMLDRYFKGEDFPAQNYIVKAGQLASQYQ', 'length': 378}, {'primaryAccession': 'Q9SXP2', 'taxonId': 39947, 'value': 'MAMWRAAAGHLLGRALGSRAAHTSAGSKKIVGVFYKGGEYADKNPNFVGCVEGALGIREWLESKGHHYIVTDDKEGLNSELEKHIEDMHVLITTPFHPAYVSAERIKKAKNLELLLTAGIGSDHIDLPAAAAAGLTVAEVTGSNTVSVAEDELMRILILLRNFLPGYQQVVHGEWNVAGIAYRAYDLEGKTVGTVGAGRIGRLLLQRLKPFNCNLLYHDRLKIDPELEKEIGAKYEEDLDAMLPKCDVIVINTPLTEKTRGMFNKERIAKMKKGVIIVNNARGAIMDTQAVADACSSGQVAGYGGDVWFPQPAPKDHPWRYMPNHAMTPHISGTTIDAQLRYAAGVKDMLDRYFKGEDFPVQNYIVKEGQLASQYQ', 'length': 376}]]\n",
      "[[{'primaryAccession': 'Q03134', 'taxonId': 227321, 'value': 'MGKVLMVLYDGGSHAKDQPGLLGTTENELGIRKWIEEQGHTLVTTSDKDGENSTFDKELVDAEVIITTPFHPGYLTAERLAKAKNLKLAVTAGIGSDHVDLDAANKTNGGITVAEVTGSNVVSVAEHVVMTILLLVRNFVPAHDQIRNGDWNVAAVAKNEFDLENKVVGTVGVGRIGERVLRRLKPFDCKELLYYDYQPLRPEVEKEIGARRVDSLEEMVSQCDVVTINCPLHEKTRGLFNKELISKMKPGSWLVNTARGAIVVKEDVAEALKSGHLRGYGGDVWFPQPAPKEHPLRYAEHPWGGGNATVPHMSGTSIDAQIRYANGTKAILDSYFSGRFDYQPQDLIVHGGDYATKAYGQREKK', 'length': 365}]]\n",
      "[[{'primaryAccession': 'P32771', 'taxonId': 559292, 'value': 'MSAATVGKPIKCIAAVAYDAKKPLSVEEITVDAPKAHEVRIKIEYTAVCHTDAYTLSGSDPEGLFPCVLGHEGAGIVESVGDDVITVKPGDHVIALYTAECGKCKFCTSGKTNLCGAVRATQGKGVMPDGTTRFHNAKGEDIYHFMGCSTFSEYTVVADVSVVAIDPKAPLDAACLLGCGVTTGFGAALKTANVQKGDTVAVFGCGTVGLSVIQGAKLRGASKIIAIDINNKKKQYCSQFGATDFVNPKEDLAKDQTIVEKLIEMTDGGLDFTFDCTGNTKIMRDALEACHKGWGQSIIIGVAAAGEEISTRPFQLVTGRVWKGSAFGGIKGRSEMGGLIKDYQKGALKVEEFITHRRPFKEINQAFEDLHNGDCLRTVLKSDEIK', 'length': 386}]]\n",
      "[[{'primaryAccession': 'P46154', 'taxonId': 303, 'value': 'MSGNRGVVYLGSGKVEVQKIDYPKMQDPRGKKIEHGVILKVVSTNICGSDQHMVRGRTTAQVGLVLGHEITGEVIEKGRDVENLQIGDLVSVPFNVACGRCRSCKEMHTGVCLTVNPARAGGAYGYVDMGDWTGGQAEYLLVPYADFNLLKLPDRDKAMEKIRDLTCLSDILPTGYHGAVTAGVGPGSTVYVAGAGPVGLAAAASARLLGAAVVIVGDLNPARLAHAKAQGFEIADLSLDTPLHEQIAALLGEPEVDCAVDAVGFEARGHGHEGAKHEAPATVLNSLMQVTRVAGKIGIPGLYVTEDPGAVDAAAKIGSLSIRFGLGWAKSHSFHTGQTPVMKYNRALMQAIMWDRINIAEVVGVQVISLDDAPRGYGEFDAGVPKKFVIDPHKTFSAA', 'length': 399}]]\n",
      "[[{'primaryAccession': 'Q9ZRI8', 'taxonId': 4513, 'value': 'MAAMWRAAARQLVDRAVGSRAAHTSAGSKKIVGVFYQAGEYADKNPNFVGCVEGALGIRDWLESKGHHYIVTDDKEGFNSELEKHIEDMHVLITTPFHPAYVTAEKIKKAKTPELLLTAGIGSDHIDLPAAAAAGLTVARVTGSNTVSVAEDELMRILILLRNFLPGYQQVVKGEWNVAGIAHRAYDLEGKTVGTVGAGRYGRLLLQRLKPFNCNLLYHDRLQINPELEKEIGAKFEEDLDAMLPKCDVVVINTPLTEKTRGMFNKEKIAKMKKGVIIVNNARGAIMDTQAVADACSSGHIAGYGGDVWFPQPAPKDHPWRYMPNHAMTPHISGTTIDAQLRYAAGVKDMLDRYFKGEEFPVENYIVKEGELASQYK', 'length': 377}]]\n",
      "[[{'primaryAccession': 'N1P3Y5', 'taxonId': 889517, 'value': 'MSKGKVLLVLYEGGKHAEEQEKLLGCIENELGIRNFIEEQGYELVTTIDKDPEPTSTVDRELKDAEIVITTPFFPAYISRNRIAEAPNLKLCVTAGVGSDHVDLEAANERKITVTEVTGSNVVSVAEHVMATILVLIRNYNGGHQQAINGEWDIAGVAKNEYDLEDKIISTVGAGRIGYRVLERLVAFNPKKLLYYDYQELPAEAINRLNEASKLFNGRGDIVQRVEKLEDMVAQSDVVTINCPLHKDSRGLFNKKLISHMKDGAYLVNTARGAICVAEDVAEAVKSGKLAGYGGDVWDKQPAPKDHPWRTMDNKDHVGNAMTVHISGTSLDAQKRYAQGVKNILNSYFSKKFDYRPQDIIVQNGSYATRAYGQKK', 'length': 376}, {'primaryAccession': 'P0CT22', 'taxonId': 889517, 'value': 'MSKGKVLLVLYEGGKHAEEQEKLLGCIENELGIRNFIEEQGYELVTTIDKDPEPTSTVDRELKDAEIVITTPFFPAYISRNRIAEAPNLKLCVTAGVGSDHVDLEAANERKITVTEVTGSNVVSVAEHVMATILVLIRNYNGGHQQAINGEWDIAGVAKNEYDLEDKIISTVGAGRIGYRVLERLVAFNPKKLLYYDYQELPAEAINRLNEASKLFNGRGDIVQRVEKLEDMVAQSDVVTINCPLHKDSRGLFNKKLISHMKDGAYLVNTARGAICVAEDVAEAVKSGKLAGYGGDVWDKQPAPKDHPWRTMDNKDHVGNAMTVHISGTSLHAQKRYAQGVKNILNSYFSKKFDYRPQDIIVQNGSYATRAYGQKK', 'length': 376}]]\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloaderdb:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader for .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clusterid</th>\n",
       "      <th>kingdomid</th>\n",
       "      <th>proteinid</th>\n",
       "      <th>length</th>\n",
       "      <th>sequence</th>\n",
       "      <th>taxon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UniRef100_Q181B5</td>\n",
       "      <td>10239</td>\n",
       "      <td>A0A125YE16</td>\n",
       "      <td>92^^&lt;http://www.w3.org/2001/XMLSchema#int&gt;</td>\n",
       "      <td>MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIA...</td>\n",
       "      <td>http://purl.uniprot.org/taxonomy/1263196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UniRef100_Q181B5</td>\n",
       "      <td>10239</td>\n",
       "      <td>A0A125YE16</td>\n",
       "      <td>92^^&lt;http://www.w3.org/2001/XMLSchema#int&gt;</td>\n",
       "      <td>MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIA...</td>\n",
       "      <td>http://purl.uniprot.org/taxonomy/1263198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UniRef100_Q181B5</td>\n",
       "      <td>10239</td>\n",
       "      <td>A0A125YE16</td>\n",
       "      <td>92^^&lt;http://www.w3.org/2001/XMLSchema#int&gt;</td>\n",
       "      <td>MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIA...</td>\n",
       "      <td>http://purl.uniprot.org/taxonomy/1266660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UniRef100_Q181B5</td>\n",
       "      <td>10239</td>\n",
       "      <td>A0A125YE16</td>\n",
       "      <td>92^^&lt;http://www.w3.org/2001/XMLSchema#int&gt;</td>\n",
       "      <td>MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIA...</td>\n",
       "      <td>http://purl.uniprot.org/taxonomy/1269277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UniRef100_Q181B5</td>\n",
       "      <td>10239</td>\n",
       "      <td>A0A125YE16</td>\n",
       "      <td>92^^&lt;http://www.w3.org/2001/XMLSchema#int&gt;</td>\n",
       "      <td>MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIA...</td>\n",
       "      <td>http://purl.uniprot.org/taxonomy/1269278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          clusterid   kingdomid   proteinid  \\\n",
       "0  UniRef100_Q181B5       10239  A0A125YE16   \n",
       "1  UniRef100_Q181B5       10239  A0A125YE16   \n",
       "2  UniRef100_Q181B5       10239  A0A125YE16   \n",
       "3  UniRef100_Q181B5       10239  A0A125YE16   \n",
       "4  UniRef100_Q181B5       10239  A0A125YE16   \n",
       "\n",
       "                                       length  \\\n",
       "0  92^^<http://www.w3.org/2001/XMLSchema#int>   \n",
       "1  92^^<http://www.w3.org/2001/XMLSchema#int>   \n",
       "2  92^^<http://www.w3.org/2001/XMLSchema#int>   \n",
       "3  92^^<http://www.w3.org/2001/XMLSchema#int>   \n",
       "4  92^^<http://www.w3.org/2001/XMLSchema#int>   \n",
       "\n",
       "                                            sequence  \\\n",
       "0  MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIA...   \n",
       "1  MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIA...   \n",
       "2  MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIA...   \n",
       "3  MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIA...   \n",
       "4  MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIA...   \n",
       "\n",
       "                                      taxon  \n",
       "0  http://purl.uniprot.org/taxonomy/1263196  \n",
       "1  http://purl.uniprot.org/taxonomy/1263198  \n",
       "2  http://purl.uniprot.org/taxonomy/1266660  \n",
       "3  http://purl.uniprot.org/taxonomy/1269277  \n",
       "4  http://purl.uniprot.org/taxonomy/1269278  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# with open('../data/raw/uniref100_sample_n20.csv', newline='') as csvfile:\n",
    "#     csvreader = csv.reader(csvfile)\n",
    "#     for row in csvreader:\n",
    "#         print(row)  # Each row is a list of values\n",
    "\n",
    "df = pd.read_csv('../data/raw/uniref100_sample_n20.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "\n",
    "        self.data = data\n",
    "        data[' length'] = data[' length'].str.replace(r'\\^\\^<.*?>', '', regex=True).astype(int)\n",
    "        data[' taxon'] = data[' taxon'].str.extract(r'h.*/(\\d+)/?$')[0].astype(int)\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        \n",
    "        item = self.data.iloc[index]\n",
    "\n",
    "        # Extract relevant fields\n",
    "        sequence = item[' sequence']  # The protein sequence\n",
    "        length = item[' length']   # Length of the sequence\n",
    "        taxon_id = item[' kingdomid']  # Taxon ID\n",
    "        primary_accession = item[' proteinid']  # Primary accession\n",
    "\n",
    "        return {\n",
    "            'sequence': sequence,  # Return sequence as a string (you could modify this later)\n",
    "            'length': length,\n",
    "            'taxon_id': taxon_id,\n",
    "            'primary_accession': primary_accession\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#df = pd.read_csv('../../data_uniprot/cleaned_file.csv')\n",
    "#df = pd.read_csv('../data/raw/uniref100_sample_n20.csv')\n",
    "\n",
    "#df[' length'] = df[' length'].str.replace(r'\\^\\^<.*?>', '', regex=True).astype(int)\n",
    "#df[' taxon'] = df[' taxon'].str.extract(r'h.*/(\\d+)/?$')[0].astype(int)\n",
    "#df[' length'] = df[' length'].str.replace(r'\\^\\^<.*?>', '', regex=True)#.astype(int)\n",
    "#item = df.iloc[1]\n",
    "#df.head()\n",
    "#len(df)\n",
    "#print(item[\" length\"])\n",
    "# TO do:\n",
    "# Remove strings from length\n",
    "# Convert numbers string into  int.\n",
    "#invalid_values = df[~df[' length'].str.replace(r'\\^\\^<.*?>', '', regex=True).str.isnumeric()]\n",
    "#print(invalid_values)\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35848003\n"
     ]
    }
   ],
   "source": [
    "header_row = df.iloc[0]\n",
    "repeated_headers = (df == header_row).all(axis=1)\n",
    "df_cleaned = df[~repeated_headers].reset_index(drop=True)\n",
    "print(len(df_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35848003\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get the header row\n",
    "header_row = df.iloc[0].values\n",
    "\n",
    "# Find rows that match the header row\n",
    "repeated_headers = np.all(df.values == header_row, axis=1)\n",
    "\n",
    "# Filter out the repeated headers\n",
    "df_cleaned = df.loc[~repeated_headers].reset_index(drop=True)\n",
    "print(len(df_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clusterid</th>\n",
       "      <th>kingdomid</th>\n",
       "      <th>proteinid</th>\n",
       "      <th>length</th>\n",
       "      <th>sequence</th>\n",
       "      <th>taxon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>clusterid</td>\n",
       "      <td>kingdomid</td>\n",
       "      <td>proteinid</td>\n",
       "      <td>length</td>\n",
       "      <td>sequence</td>\n",
       "      <td>taxon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>clusterid</td>\n",
       "      <td>kingdomid</td>\n",
       "      <td>proteinid</td>\n",
       "      <td>length</td>\n",
       "      <td>sequence</td>\n",
       "      <td>taxon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>clusterid</td>\n",
       "      <td>kingdomid</td>\n",
       "      <td>proteinid</td>\n",
       "      <td>length</td>\n",
       "      <td>sequence</td>\n",
       "      <td>taxon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>clusterid</td>\n",
       "      <td>kingdomid</td>\n",
       "      <td>proteinid</td>\n",
       "      <td>length</td>\n",
       "      <td>sequence</td>\n",
       "      <td>taxon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      clusterid   kingdomid   proteinid   length   sequence   taxon\n",
       "1000  clusterid   kingdomid   proteinid   length   sequence   taxon\n",
       "2001  clusterid   kingdomid   proteinid   length   sequence   taxon\n",
       "3002  clusterid   kingdomid   proteinid   length   sequence   taxon\n",
       "4003  clusterid   kingdomid   proteinid   length   sequence   taxon"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(invalid_values)\n",
    "header_row = df.iloc[0]  # assuming the first row is the actual header\n",
    "#repeated_headers = (df == header_row).all(axis=1)\n",
    "\n",
    "# Filter out the repeated headers\n",
    "#df_cleaned = df[~repeated_headers].reset_index(drop=True)\n",
    "len(df)\n",
    "len(df_cleaned)\n",
    "\n",
    "df.iloc[10000]\n",
    "df[~df[' length'].str.replace(r'\\^\\^<.*?>', '', regex=True).str.isnumeric()]\n",
    "\n",
    "#df.columns = df.columns.str.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "\n",
    "        self.data = data\n",
    "        data[' length'] = data[' length'].str.replace(r'\\^\\^<.*?>', '', regex=True).astype(int)\n",
    "        data[' taxon'] = data[' taxon'].str.extract(r'h.*/(\\d+)/?$')[0].astype(int)\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        \n",
    "        item = self.data.iloc[index]\n",
    "\n",
    "        # Extract relevant fields\n",
    "        sequence = item[' sequence']  # The protein sequence\n",
    "        length = item[' length']   # Length of the sequence\n",
    "        taxon_id = item[' taxon']  # Taxon ID\n",
    "        primary_accession = item[' proteinid']  # Primary accession\n",
    "\n",
    "        return {\n",
    "            'sequence': sequence,  # Return sequence as a string (you could modify this later)\n",
    "            'length': length,\n",
    "            'taxon_id': taxon_id,\n",
    "            'primary_accession': primary_accession\n",
    "        }\n",
    "    \n",
    "class TaxonIdSampler(Sampler):\n",
    "    def __init__(self, dataset: Dataset, batch_size, length_bin_size=5, shuffle=True):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.length_bin_size = length_bin_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # Group sample indices by taxonId\n",
    "        self.taxon_length_bins = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "        for idx, sample in enumerate(dataset):\n",
    "            taxon_id = sample['taxon_id']\n",
    "            sequence_length = sample['length']\n",
    "            length_bin = (sequence_length // length_bin_size) * length_bin_size  # integer division to know in which bucket the sequence is\n",
    "\n",
    "            # Ensure that length_bin is properly initialized\n",
    "            self.taxon_length_bins[taxon_id][length_bin].append(idx)\n",
    "\n",
    "        '''\n",
    "        structure of self.taxon_length_bins:\n",
    "\n",
    "        {\n",
    "            taxon_id_1: {\n",
    "                length_bin_1: [sample_idx_1, sample_idx_2, ...],\n",
    "                length_bin_2: [sample_idx_3, sample_idx_4, ...],\n",
    "                ...\n",
    "            },\n",
    "            taxon_id_2: {\n",
    "                length_bin_3: [sample_idx_5, sample_idx_6, ...],\n",
    "                ...\n",
    "            },\n",
    "        }\n",
    "        '''\n",
    "        \n",
    "        # Prepare batches based on taxon groups\n",
    "        self.batches = []\n",
    "\n",
    "        for taxon, length_bins in self.taxon_length_bins.items():\n",
    "            for length_bin, indices in length_bins.items():\n",
    "                if self.shuffle:\n",
    "                    random.shuffle(indices)  # Shuffle the indices if needed\n",
    "                for i in range(0, len(indices), batch_size):\n",
    "                    self.batches.append(indices[i:i + batch_size])\n",
    "\n",
    "        # Shuffle the batches if needed\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.batches)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.batches:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batches)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#dataset = ProteinDataset(data = df)\n",
    "df[' length']\n",
    "\n",
    "#dataset[0]\n",
    "#df[' length'].unique()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#sample = dataset[0]\n",
    "\n",
    "#print(dataset[0])\n",
    "# print(\"Original Sequence:\", sample['sequence'])\n",
    "# print(\"Masked Sequence:\", sample['masked_sequence'])\n",
    "# print(\"Mask:\", sample['mask'])\n",
    "# print(\"Length:\", sample['length'])\n",
    "# print(\"Taxon ID:\", sample['taxon_id'])\n",
    "# print(\"Primary Accession:\", sample['primary_accession'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetcsv = ProteinDataset(data = df)\n",
    "samplercsv = TaxonIdSampler(dataset = datasetcsv, batch_size = 5, shuffle = True)\n",
    "dataloadercsv = DataLoader(dataset = datasetcsv, batch_sampler=samplercsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': ['MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIAMPSRKVGEGNFRDIAHPINAEMRQVLEDAVLQAYHEALVQWEVAAE', 'MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIAMPSRKVGEGNFRDIAHPINAEMRQVLEDAVLQAYHEALVQWEVAAE', 'MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIAMPSRKVGEGNFRDIAHPINAEMRQVLEDAVLQAYHEALVQWEVAAE', 'MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIAMPSRKVGEGNFRDIAHPINAEMRQVLEDAVLQAYHEALVQWEVAAE', 'MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIAMPSRKVGEGNFRDIAHPINAEMRQVLEDAVLQAYHEALVQWEVAAE'], 'length': tensor([92, 92, 92, 92, 92]), 'taxon_id': tensor([10239, 10239, 10239, 10239, 10239]), 'primary_accession': ['A0A125YE16', 'A0A125YE16', 'A0A125YE16', 'A0A125YE16', 'A0A125YE16']}\n",
      "{'sequence': ['MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIAMPSRKVGEGNFRDIAHPINAEMRQVLEDAVLQAYHEALVQWEVAAE', 'MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIAMPSRKVGEGNFRDIAHPINAEMRQVLEDAVLQAYHEALVQWEVAAE', 'MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIAMPSRKVGEGNFRDIAHPINAEMRQVLEDAVLQAYHEALVQWEVAAE', 'MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIAMPSRKVGEGNFRDIAHPINAEMRQVLEDAVLQAYHEALVQWEVAAE', 'MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIAMPSRKVGEGNFRDIAHPINAEMRQVLEDAVLQAYHEALVQWEVAAE'], 'length': tensor([92, 92, 92, 92, 92]), 'taxon_id': tensor([10239, 10239, 10239, 10239, 10239]), 'primary_accession': ['A0A125YE16', 'A0A125YE16', 'A0A125YE16', 'A0A125YE16', 'A0A125YE16']}\n",
      "{'sequence': ['MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIAMPSRKVGEGNFRDIAHPINAEMRQVLEDAVLQAYHEALVQWEVAAE', 'MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIAMPSRKVGEGNFRDIAHPINAEMRQVLEDAVLQAYHEALVQWEVAAE', 'MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIAMPSRKVGEGNFRDIAHPINAEMRQVLEDAVLQAYHEALVQWEVAAE', 'MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIAMPSRKVGEGNFRDIAHPINAEMRQVLEDAVLQAYHEALVQWEVAAE', 'MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIAMPSRKVGEGNFRDIAHPINAEMRQVLEDAVLQAYHEALVQWEVAAE'], 'length': tensor([92, 92, 92, 92, 92]), 'taxon_id': tensor([10239, 10239, 10239, 10239, 10239]), 'primary_accession': ['A0A125YE16', 'A0A125YE16', 'A0A125YE16', 'A0A125YE16', 'A0A125YE16']}\n",
      "{'sequence': ['MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIAMPSRKVGEGNFRDIAHPINAEMRQVLEDAVLQAYHEALVQWEVAAE', 'MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIAMPSRKVGEGNFRDIAHPINAEMRQVLEDAVLQAYHEALVQWEVAAE', 'MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIAMPSRKVGEGNFRDIAHPINAEMRQVLEDAVLQAYHEALVQWEVAAE', 'MKITDVRVRKLTEEGKMKCIVSITFDNLFVVHDIKVIEGHNGLFIAMPSRKVGEGNFRDIAHPINAEMRQVLEDAVLQAYHEALVQWEVAAE'], 'length': tensor([92, 92, 92, 92]), 'taxon_id': tensor([10239, 10239, 10239, 10239]), 'primary_accession': ['A0A125YE16', 'A0A125YE16', 'A0A125YE16', 'A0A125YE16']}\n"
     ]
    }
   ],
   "source": [
    "# d1 = ProteinDataset(data = df)\n",
    "# sampler = CustomSampler(d1, shuffle=True)\n",
    "# dataloader = DataLoader(d1, batch_size=5, sampler=sampler)\n",
    "\n",
    "# Iterate over the DataLoader\n",
    "for batch in dataloadercsv:\n",
    "    print(batch)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaxonIdSampler(Sampler):\n",
    "    def __init__(self, dataset: Dataset, batch_size, length_bin_size=5, shuffle=True):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.length_bin_size = length_bin_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # Group sample indices by taxonId\n",
    "        self.taxon_length_bins = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "        for idx, sample in enumerate(dataset):\n",
    "            taxon_id = sample['taxon_id']\n",
    "            sequence_length = sample['length']\n",
    "            length_bin = (sequence_length // length_bin_size) * length_bin_size  # integer division to know in which bucket the sequence is\n",
    "\n",
    "            # Ensure that length_bin is properly initialized\n",
    "            self.taxon_length_bins[taxon_id][length_bin].append(idx)\n",
    "\n",
    "        '''\n",
    "        structure of self.taxon_length_bins:\n",
    "\n",
    "        {\n",
    "            taxon_id_1: {\n",
    "                length_bin_1: [sample_idx_1, sample_idx_2, ...],\n",
    "                length_bin_2: [sample_idx_3, sample_idx_4, ...],\n",
    "                ...\n",
    "            },\n",
    "            taxon_id_2: {\n",
    "                length_bin_3: [sample_idx_5, sample_idx_6, ...],\n",
    "                ...\n",
    "            },\n",
    "        }\n",
    "        '''\n",
    "        \n",
    "        # Prepare batches based on taxon groups\n",
    "        self.batches = []\n",
    "\n",
    "        for taxon, length_bins in self.taxon_length_bins.items():\n",
    "            for length_bin, indices in length_bins.items():\n",
    "                if self.shuffle:\n",
    "                    random.shuffle(indices)  # Shuffle the indices if needed\n",
    "                for i in range(0, len(indices), batch_size):\n",
    "                    self.batches.append(indices[i:i + batch_size])\n",
    "\n",
    "        # Shuffle the batches if needed\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.batches)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.batches:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "class TaxonIdSampler(Sampler):\n",
    "    def __init__(self, dataset, batch_size, length_bin_size=5, mask_percentage=0.15, shuffle=True, seed=42):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.length_bin_size = length_bin_size\n",
    "        self.mask_percentage = mask_percentage\n",
    "        self.shuffle = shuffle\n",
    "        self.seed = seed\n",
    "\n",
    "        # Group sample indices by taxonId and length bin\n",
    "        self.taxon_length_bins = defaultdict(lambda: defaultdict(list))\n",
    "        for idx, sample in enumerate(dataset):\n",
    "            taxon_id = sample['taxon_id']\n",
    "            sequence_length = sample['length']\n",
    "            length_bin = (sequence_length // length_bin_size) * length_bin_size\n",
    "            self.taxon_length_bins[taxon_id][length_bin].append(idx)\n",
    "\n",
    "        # Prepare batches based on taxon groups\n",
    "        self.batches = []\n",
    "        for taxon, length_bins in self.taxon_length_bins.items():\n",
    "            for length_bin, indices in length_bins.items():\n",
    "                if self.shuffle:\n",
    "                    random.shuffle(indices)\n",
    "                for i in range(0, len(indices), batch_size):\n",
    "                    self.batches.append(indices[i:i + batch_size])\n",
    "\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.batches)\n",
    "\n",
    "    def __iter__(self):\n",
    "        random.seed(self.seed)  # Ensure reproducibility of masking per epoch\n",
    "        for batch_indices in self.batches:\n",
    "            batch_sequences = [self.dataset[idx]['sequence'] for idx in batch_indices]\n",
    "            max_len = max(len(seq) for seq in batch_sequences)\n",
    "\n",
    "            # Mask and pad each sequence in the batch\n",
    "            masked_sequences = []\n",
    "            masks = []\n",
    "            for idx in batch_indices:\n",
    "                sequence_tensor = torch.tensor([ord(c) for c in self.dataset[idx]['sequence']])\n",
    "                padded_sequence, mask = self.mask_and_pad(sequence_tensor, max_len)\n",
    "                masked_sequences.append(padded_sequence)\n",
    "                masks.append(mask)\n",
    "\n",
    "            # Yield the masked and padded batch\n",
    "            yield {\n",
    "                'masked_sequences': torch.stack(masked_sequences),\n",
    "                'masks': torch.stack(masks),\n",
    "                'lengths': torch.tensor([len(self.dataset[idx]['sequence']) for idx in batch_indices]),\n",
    "                'taxon_id': torch.tensor([self.dataset[idx]['taxon_id'] for idx in batch_indices])\n",
    "            }\n",
    "\n",
    "    def mask_and_pad(self, sequence, max_len):\n",
    "        \"\"\"Apply masking and pad the sequence to max_len.\"\"\"\n",
    "        num_mask = int(self.mask_percentage * len(sequence))\n",
    "        mask = torch.zeros(max_len, dtype=torch.bool)\n",
    "        masked_sequence = torch.full((max_len,), 0, dtype=sequence.dtype)  # Assuming '0' is the mask token\n",
    "        \n",
    "        # Copy sequence to masked_sequence\n",
    "        masked_sequence[:len(sequence)] = sequence\n",
    "        mask_indices = random.sample(range(len(sequence)), num_mask)\n",
    "\n",
    "        for idx in mask_indices:\n",
    "            prob = random.random()\n",
    "            if prob < 0.8:\n",
    "                masked_sequence[idx] = 0  # Mask token\n",
    "                mask[idx] = True\n",
    "            elif prob < 0.9:\n",
    "                masked_sequence[idx] = random.randint(1, 20)  # Random integer mutation\n",
    "            # 10% remains unchanged\n",
    "\n",
    "        return masked_sequence, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_collate_fn(batch):\n",
    "    # Return the batch as-is (a list of dictionaries)\n",
    "    return batch\n",
    "\n",
    "\n",
    "import torch\n",
    "import random\n",
    "\n",
    "def batch_masking_collate_fn(batch, mask_ratio=0.15, mask_prob=0.8, mutate_prob=0.1, unchanged_prob=0.1, seed=42):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # Extract sequences and determine the max length in this batch\n",
    "    sequences = [item['sequence'] for item in batch]\n",
    "    max_len = max(len(seq) for seq in sequences)\n",
    "\n",
    "    masked_batch = []\n",
    "    for item in batch:\n",
    "        sequence = item['sequence']\n",
    "        seq_len = len(sequence)\n",
    "        \n",
    "        # Decide which positions to mask\n",
    "        num_masked = int(mask_ratio * seq_len)\n",
    "        mask_indices = random.sample(range(seq_len), num_masked)\n",
    "        \n",
    "        masked_sequence = list(sequence)  # Convert to list for mutability\n",
    "        \n",
    "        for idx in mask_indices:\n",
    "            choice = random.choices(\n",
    "                ['mask', 'mutate', 'unchanged'], \n",
    "                weights=[mask_prob, mutate_prob, unchanged_prob]\n",
    "            )[0]\n",
    "            \n",
    "            if choice == 'mask':\n",
    "                masked_sequence[idx] = '[MASK]'  # Use [MASK] token, or any placeholder for masked\n",
    "            elif choice == 'mutate':\n",
    "                masked_sequence[idx] = random.choice('ACDEFGHIKLMNPQRSTVWY')  # Random amino acid (mutation)\n",
    "            # 'unchanged' leaves it as is\n",
    "\n",
    "        # Update item with masked sequence\n",
    "        item['masked_sequence'] = ''.join(masked_sequence)\n",
    "\n",
    "    # Pad sequences and masked sequences to max_len\n",
    "    for item in batch:\n",
    "        sequence = item['masked_sequence']\n",
    "        padding_len = max_len - len(sequence)\n",
    "        padded_sequence = sequence + ' ' * padding_len  # Use a suitable padding token here\n",
    "        item['padded_sequence'] = padded_sequence\n",
    "    \n",
    "    # Return the batch in a way compatible with DataLoader\n",
    "    return {\n",
    "        'padded_sequences': torch.tensor([list(item['padded_sequence']) for item in batch]),\n",
    "        'taxon_id': [item['taxon_id'] for item in batch],\n",
    "        'primary_accession': [item['primary_accession'] for item in batch]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TaxonBatchSampler with your dataset\n",
    "batch_size = 50\n",
    "dataset = ProteinDataset(data = df)\n",
    "sampler = TaxonIdSampler(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_sampler=sampler)\n",
    "\n",
    "# Iterate over the DataLoader\n",
    "#for batch in dataloader:\n",
    " #   print(batch['sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_rep(results, batch_lens):\n",
    "    \"\"\"\n",
    "    Get sequence representations from esm_compute\n",
    "    \"\"\"\n",
    "    token_representations = results[\"representations\"][33]\n",
    " \n",
    "    # Generate per-sequence representations via averaging\n",
    "    sequence_representations = []\n",
    "    for i, tokens_len in enumerate(batch_lens):\n",
    "        sequence_representations.append(token_representations[i, 1: tokens_len - 1].mean(0))\n",
    " \n",
    "    return sequence_representations\n",
    " \n",
    " \n",
    "def get_logits(results):\n",
    "    \"\"\"\n",
    "    Get logits from esm_compute\n",
    "    \"\"\"\n",
    "    logits = results[\"logits\"]\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rogall/miniforge3/envs/ml/lib/python3.12/site-packages/esm/pretrained.py:215: UserWarning: Regression weights not found, predicting contacts will not produce correct results.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "seqs = [\"AGAVCTGAKLI\", \"AGHRFLIKLKI\"]\n",
    "results, batch_lens, batch_labels, alphabet = esm_compute(seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First logits computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGITS = []\n",
    "REPRESENTATIOS = []\n",
    "for batch in dataloader:\n",
    "    #try:\n",
    "        sequences = batch['sequence']\n",
    "        names = batch['primary_accession']\n",
    "\n",
    "        results, batch_lens, batch_labels, alphabet = esm_compute(seqs = sequences, names = names )\n",
    "        \n",
    "        sequence_representations = get_seq_rep(results, batch_lens)\n",
    "\n",
    "        for i, x in enumerate(sequence_representations):\n",
    "            torch.save(x, f\"../demo/demo_results/{names[i]}.pt\")\n",
    "\n",
    "   # except:\n",
    "        pass\n",
    "    # Print or process the data\n",
    "    # print(\"Sequences:\", seqs)\n",
    "    # print(\"Names:\", names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mf/wh6pc4zs5bdf1rhq4yhjvvf00000gp/T/ipykernel_59713/1399910260.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tensors = [torch.load('reps/'+f) for f in os.listdir('reps') if f.endswith('.pt')]\n"
     ]
    }
   ],
   "source": [
    "tensors = [torch.load('reps/'+f) for f in os.listdir('reps') if f.endswith('.pt')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'primaryAccession': ['Q17335'], 'taxonId': tensor([6239]), 'value': ['MSSTAGQVINCKAAVAWSAKAPLSIETIQVAPPKAHEVRVKILYTAVCHTDAYTLDGHDPEGLFPVVLGHEGSGIVESVGEGVTGFAPGDHVVPLYVPQCKECEYCKNPKTNLCQKIRISQGNGFMPDGSSRFTCNGKQLFHFMGCSTFSEYTVVADISLCKVNPEAPLEKVSLLGCGISTGYGAVLNTCKVEEGSTVAVWGLGAVGLAVIMGAKAAGAKKIVGIDLIESKFESAKFFGATECINPKSVELPEGKSFQAWLVEQFDGGFDYTFECIGNVHTMRQALEAAHKGWGVSCIIGVAGAGQEIATRPFQLVTGRTWKGTAFGGWKSVESVPRLVDDYMNKKLLIDEFITHRWNIDDINTAFDVLHKGESLRSVLAFEKI'], 'length': tensor([384])}]\n",
      "[{'primaryAccession': ['C8ZHD6'], 'taxonId': tensor([643680]), 'value': ['MSKGKVLLVLYEGGKHAEEQEKLLGCIENELGIRNFIEEQGYELVTTIDKDPEPTSTVDRELKDAEIVITTPFFPAYISRNRIAEAPNLKLCVTAGVGSDHVDLEAANERKITVTEVTGSNVVSVAEHVMATILVLIRNYNGGHQQAINGEWDIAGVAKNEYDLEDKIISTVGAGRIGYRVLERLVAFNPKKLLYYDYQELPAEAINRLNEASKLFNGRGDIVQRVEKLEDMVAQSDVVTINCPLHKDSRGLFNKKLISHMKDGAYLVNTARGAICVAEDVAEAVKSGKLAGYGGDVWDKQPAPKDHPWRTMDNKDHVGNAMTVHISGTSLDAQKRYAQGVKNILNSYFSKKFDYRPQDIIVQNGSYATRAYGQKK'], 'length': tensor([376])}]\n",
      "[{'primaryAccession': ['Q03134'], 'taxonId': tensor([227321]), 'value': ['MGKVLMVLYDGGSHAKDQPGLLGTTENELGIRKWIEEQGHTLVTTSDKDGENSTFDKELVDAEVIITTPFHPGYLTAERLAKAKNLKLAVTAGIGSDHVDLDAANKTNGGITVAEVTGSNVVSVAEHVVMTILLLVRNFVPAHDQIRNGDWNVAAVAKNEFDLENKVVGTVGVGRIGERVLRRLKPFDCKELLYYDYQPLRPEVEKEIGARRVDSLEEMVSQCDVVTINCPLHEKTRGLFNKELISKMKPGSWLVNTARGAIVVKEDVAEALKSGHLRGYGGDVWFPQPAPKEHPLRYAEHPWGGGNATVPHMSGTSIDAQIRYANGTKAILDSYFSGRFDYQPQDLIVHGGDYATKAYGQREKK'], 'length': tensor([365])}]\n",
      "[{'primaryAccession': ['Q9ZRI8'], 'taxonId': tensor([4513]), 'value': ['MAAMWRAAARQLVDRAVGSRAAHTSAGSKKIVGVFYQAGEYADKNPNFVGCVEGALGIRDWLESKGHHYIVTDDKEGFNSELEKHIEDMHVLITTPFHPAYVTAEKIKKAKTPELLLTAGIGSDHIDLPAAAAAGLTVARVTGSNTVSVAEDELMRILILLRNFLPGYQQVVKGEWNVAGIAHRAYDLEGKTVGTVGAGRYGRLLLQRLKPFNCNLLYHDRLQINPELEKEIGAKFEEDLDAMLPKCDVVVINTPLTEKTRGMFNKEKIAKMKKGVIIVNNARGAIMDTQAVADACSSGHIAGYGGDVWFPQPAPKDHPWRYMPNHAMTPHISGTTIDAQLRYAAGVKDMLDRYFKGEEFPVENYIVKEGELASQYK'], 'length': tensor([377])}]\n",
      "[{'primaryAccession': ['Q07103'], 'taxonId': tensor([367110]), 'value': ['MVKVLAVLYDGGKHGEEVPELLGTIQNELGLRKWLEDQGHTLVTTCDKDGENSTFDKELEDAEIIITTPFHPGYLTAERLARAKKLKLAVTAGIGSDHVDLNAANKTNGGITVAEVTGSNVVSVAEHVLMTILVLVRNFVPAHEQIQEGRWDVAEAAKNEFDLEGKVVGTVGVGRIGERVLRRLKPFDCKELLYYDYQPLSAEKEAEIGCRRVADLEEMLAQCDVVTINCPLHEKTQGLFNKELISKMKKGSWLVNTARGAIVVKEDVAEALKSGHLRGYGGDVWFPQPAPQDHPLRYAKNPFGGGNAMVPHMSGTSLDAQKRYAAGTKAIIESYLSGKHDYRPEDLIVYGGDYATKSYGERERAKAAAAAAKSA'], 'length': tensor([375])}]\n",
      "[{'primaryAccession': ['P33677'], 'taxonId': tensor([870730]), 'value': ['MKVVLVLYDAGKHAQDEERLYGCTENALGIRDWLEKQGHDVVVTSDKEGQNSVLEKNISDADVIISTPFHPAYITKERIDKAKKLKLLVVAGVGSDHIDLDYINQSGRDISVLEVTGSNVVSVAEHVVMTMLVLVRNFVPAHEQIISGGWNVAEIAKDSFDIEGKVIATIGAGRIGYRVLERLVAFNPKELLYYDYQSLSKEAEEKVGARRVHDIKELVAQADIVTINCPLHAGSKGLVNAELLKHFKKGAWLVNTARGAICVAEDVAAAVKSGQLRGYGGDVWFPQPAPKDHPWRSMANKYGAGNAMTPHYSGSVIDAQVRYAQGTKNILESFFTQKFDYRPQDIILLNGKYKTKSYGADK'], 'length': tensor([362])}]\n",
      "[{'primaryAccession': ['N1P3Y5'], 'taxonId': tensor([889517]), 'value': ['MSKGKVLLVLYEGGKHAEEQEKLLGCIENELGIRNFIEEQGYELVTTIDKDPEPTSTVDRELKDAEIVITTPFFPAYISRNRIAEAPNLKLCVTAGVGSDHVDLEAANERKITVTEVTGSNVVSVAEHVMATILVLIRNYNGGHQQAINGEWDIAGVAKNEYDLEDKIISTVGAGRIGYRVLERLVAFNPKKLLYYDYQELPAEAINRLNEASKLFNGRGDIVQRVEKLEDMVAQSDVVTINCPLHKDSRGLFNKKLISHMKDGAYLVNTARGAICVAEDVAEAVKSGKLAGYGGDVWDKQPAPKDHPWRTMDNKDHVGNAMTVHISGTSLDAQKRYAQGVKNILNSYFSKKFDYRPQDIIVQNGSYATRAYGQKK'], 'length': tensor([376])}, {'primaryAccession': ['P0CT22'], 'taxonId': tensor([889517]), 'value': ['MSKGKVLLVLYEGGKHAEEQEKLLGCIENELGIRNFIEEQGYELVTTIDKDPEPTSTVDRELKDAEIVITTPFFPAYISRNRIAEAPNLKLCVTAGVGSDHVDLEAANERKITVTEVTGSNVVSVAEHVMATILVLIRNYNGGHQQAINGEWDIAGVAKNEYDLEDKIISTVGAGRIGYRVLERLVAFNPKKLLYYDYQELPAEAINRLNEASKLFNGRGDIVQRVEKLEDMVAQSDVVTINCPLHKDSRGLFNKKLISHMKDGAYLVNTARGAICVAEDVAEAVKSGKLAGYGGDVWDKQPAPKDHPWRTMDNKDHVGNAMTVHISGTSLHAQKRYAQGVKNILNSYFSKKFDYRPQDIIVQNGSYATRAYGQKK'], 'length': tensor([376])}]\n",
      "[{'primaryAccession': ['P11766'], 'taxonId': tensor([9606]), 'value': ['MANEVIKCKAAVAWEAGKPLSIEEIEVAPPKAHEVRIKIIATAVCHTDAYTLSGADPEGCFPVILGHEGAGIVESVGEGVTKLKAGDTVIPLYIPQCGECKFCLNPKTNLCQKIRVTQGKGLMPDGTSRFTCKGKTILHYMGTSTFSEYTVVADISVAKIDPLAPLDKVCLLGCGISTGYGAAVNTAKLEPGSVCAVFGLGGVGLAVIMGCKVAGASRIIGVDINKDKFARAKEFGATECINPQDFSKPIQEVLIEMTDGGVDYSFECIGNVKVMRAALEACHKGWGVSVVVGVAASGEEIATRPFQLVTGRTWKGTAFGGWKSVESVPKLVSEYMSKKIKVDEFVTHNLSFDEINKAFELMHSGKSIRTVVKI'], 'length': tensor([374])}]\n",
      "[{'primaryAccession': ['A6ZN46'], 'taxonId': tensor([307796]), 'value': ['MSKGKVLLVLYEGGKHAEEQEKLLGCIENELGIRNFIEEQGYELVTTIDKDPEPTSTVDRELKDAEIVITTPFFPAYISRNRIAEAPNLKLCVTAGVGSDHVDLEAANERKITVTEVTGSNVVSVAEHVMATILVLIRNYNGGHQQAINGEWDIAGVAKNEYDLEDKIISTVGAGRIGYRVLERLVAFNPKKLLYYDYQELPAEAINRLNEASKLFNGRGDIVQRVEKLEDMVAQSDVVTINCPLHKDSRGLFNKKLISHMKDGAYLVNTARGAICVAEDVAEAVKSGKLAGYGGDVWDKQPAPKDHPWRTMDNKDHVGNAMTVHISGTSLDAQKRYAQGVKNILNSYFSKKFDYRPQDIIVQNGSYATRAYGQKK'], 'length': tensor([376])}]\n",
      "[{'primaryAccession': ['Q08911'], 'taxonId': tensor([559292]), 'value': ['MSKGKVLLVLYEGGKHAEEQEKLLGCIENELGIRNFIEEQGYELVTTIDKDPEPTSTVDRELKDAEIVITTPFFPAYISRNRIAEAPNLKLCVTAGVGSDHVDLEAANERKITVTEVTGSNVVSVAEHVMATILVLIRNYNGGHQQAINGEWDIAGVAKNEYDLEDKIISTVGAGRIGYRVLERLVAFNPKKLLYYDYQELPAEAINRLNEASKLFNGRGDIVQRVEKLEDMVAQSDVVTINCPLHKDSRGLFNKKLISHMKDGAYLVNTARGAICVAEDVAEAVKSGKLAGYGGDVWDKQPAPKDHPWRTMDNKDHVGNAMTVHISGTSLDAQKRYAQGVKNILNSYFSKKFDYRPQDIIVQNGSYATRAYGQKK'], 'length': tensor([376])}]\n",
      "[{'primaryAccession': ['Q3ZC42'], 'taxonId': tensor([9913]), 'value': ['MANQVIKCKAAVAWEAGKPLSIEEVEVAPPKAHEVRIKIIATAVCHTDAYTLSGADPEGNYPVILGHEGAGIVESVGEGVTKLKAGDTVIPLYIPQCGECKFCLNPKTNLCQKIRVTQGKGLMPDGTSRFTCKGKTILHYMGTSTFSEYTVVADISVAKIDPLAPLDKVCLLGCGISTGYGAALNAAKVEPGSTCAVFGLGGVGLAVIMGCKMAGAARIIGVDINKDKFARAKEFGASECINPQDFSKPIQEVLIEMTDGGVDYSFECIGNVKVMRAALEACHKGWGISVVVGVAASGEEIATRPFQLVTGRTWKGTAFGGWKSVESVPKLVSEYMSKKIKVDEFVTHSLPFDQINEAFDLMHAGKSIRTVVKL'], 'length': tensor([374])}]\n",
      "[{'primaryAccession': ['Q67U69'], 'taxonId': tensor([39947]), 'value': ['MAMWRAPSAAGQLLGRALASTAAQTSAGSKKVVGVFYKGGEYADKNPNFVGCVDSALGIRGWLESKGHRYIVTDDKEGINCELEKHIEDAHVLITTPFHPAYITAERIKKAKNLELLLTAGVGSDHIDLPAAAAAGLTVAEITGSNTVSVAEDQLMRILLLLRNFLPGHHQIVNGEWNVAGIAHRTYDLEGKTVGTVGAGRIGRLLLQRLKPFNCNLMYHDRVKIDPELEKEIGAKYEEDLDAMLPKCDVVVINMPLTEKTRGMFNKERIAKMKKGVTIVNNARGAIMDTQAVADACASGHVAGYGGDVWFPQPAPKDHPWRYMPNHAMTPHCSGTTIDGQLRYAAGVKDMLDRYFKGEDFPAQNYIVKAGQLASQYQ'], 'length': tensor([378])}, {'primaryAccession': ['Q9SXP2'], 'taxonId': tensor([39947]), 'value': ['MAMWRAAAGHLLGRALGSRAAHTSAGSKKIVGVFYKGGEYADKNPNFVGCVEGALGIREWLESKGHHYIVTDDKEGLNSELEKHIEDMHVLITTPFHPAYVSAERIKKAKNLELLLTAGIGSDHIDLPAAAAAGLTVAEVTGSNTVSVAEDELMRILILLRNFLPGYQQVVHGEWNVAGIAYRAYDLEGKTVGTVGAGRIGRLLLQRLKPFNCNLLYHDRLKIDPELEKEIGAKYEEDLDAMLPKCDVIVINTPLTEKTRGMFNKERIAKMKKGVIIVNNARGAIMDTQAVADACSSGQVAGYGGDVWFPQPAPKDHPWRYMPNHAMTPHISGTTIDAQLRYAAGVKDMLDRYFKGEDFPVQNYIVKEGQLASQYQ'], 'length': tensor([376])}]\n",
      "[{'primaryAccession': ['Q07511'], 'taxonId': tensor([4113]), 'value': ['MAMSRVASTAARAITSPSSLVFTRELQASPGPKKIVGVFYKANEYAEMNPNFLGCAENALGIREWLESKGHQYIVTPDKEGPDCELEKHIPDLHVLISTPFHPAYVTAERIKKAKNLQLLLTAGIGSDHVDLKAAAAAGLTVAEVTGSNTVSVAEDELMRILILVRNFLPGHHQVINGEWNVAAIAHRAYDLEGKTVGTVGAGRIGRLLLQRLKPFNCNLLYHDRLKMDSELENQIGAKFEEDLDKMLSKCDIVVINTPLTEKTKGMFDKERIAKLKKGVLIVNNARGAIMDTQAVVDACNSGHIAGYSGDVWYPQPAPKDHPWRYMPNQAMTPHISGTTIDAQLRYAAGTKDMLDRYFKGEDFPAENYIVKDGELAPQYR'], 'length': tensor([381])}]\n",
      "[{'primaryAccession': ['P25437'], 'taxonId': tensor([83333]), 'value': ['MKSRAAVAFAPGKPLEIVEIDVAPPKKGEVLIKVTHTGVCHTDAFTLSGDDPEGVFPVVLGHEGAGVVVEVGEGVTSVKPGDHVIPLYTAECGECEFCRSGKTNLCVAVRETQGKGLMPDGTTRFSYNGQPLYHYMGCSTFSEYTVVAEVSLAKINPEANHEHVCLLGCGVTTGIGAVHNTAKVQPGDSVAVFGLGAIGLAVVQGARQAKAGRIIAIDTNPKKFDLARRFGATDCINPNDYDKPIKDVLLDINKWGIDHTFECIGNVNVMRAALESAHRGWGQSVIIGVAVAGQEISTRPFQLVTGRVWKGSAFGGVKGRSQLPGMVEDAMKGDIDLEPFVTHTMSLDEINDAFDLMHEGKSIRTVIRY'], 'length': tensor([369])}]\n",
      "[{'primaryAccession': ['P80572'], 'taxonId': tensor([3888]), 'value': ['ATQGQVITCKAAVAWEPNKPLTIEDVEVAPPQANEVRIQILFTALCHTDAYTLGGKDPEGLFPCILGHEAAGIVESVGEGVTDVKPGDHVIPSYQAECGECKFCKSPKTNLCGKVRAATGVGVMMADRKSRFSVKGKPIYHFMGTSTFSQYTVVHDVSVAKIHPDAPLDKVCLLGCGVPTGLGAVWNTAKVEPGSIVAIFGLGTVGLAVAEGAKSAGASRIIGIDIDSNKYDTAKNFGVTEFINPKDHEKPIQQVIIDLTDGGVDYSFECLGNVSVMRSALECCHKGWGTSVIVGVAASGQEISTRPFQLVTGRVWKGTAFGGFKSRSQVPWLVEKYLKKEIKVDEYITHNLTLLEINKAFDLLHEGQCLRCVLAVHD'], 'length': tensor([378])}]\n",
      "[{'primaryAccession': ['P32771'], 'taxonId': tensor([559292]), 'value': ['MSAATVGKPIKCIAAVAYDAKKPLSVEEITVDAPKAHEVRIKIEYTAVCHTDAYTLSGSDPEGLFPCVLGHEGAGIVESVGDDVITVKPGDHVIALYTAECGKCKFCTSGKTNLCGAVRATQGKGVMPDGTTRFHNAKGEDIYHFMGCSTFSEYTVVADVSVVAIDPKAPLDAACLLGCGVTTGFGAALKTANVQKGDTVAVFGCGTVGLSVIQGAKLRGASKIIAIDINNKKKQYCSQFGATDFVNPKEDLAKDQTIVEKLIEMTDGGLDFTFDCTGNTKIMRDALEACHKGWGQSIIIGVAAAGEEISTRPFQLVTGRVWKGSAFGGIKGRSEMGGLIKDYQKGALKVEEFITHRRPFKEINQAFEDLHNGDCLRTVLKSDEIK'], 'length': tensor([386])}]\n",
      "[{'primaryAccession': ['P46154'], 'taxonId': tensor([303]), 'value': ['MSGNRGVVYLGSGKVEVQKIDYPKMQDPRGKKIEHGVILKVVSTNICGSDQHMVRGRTTAQVGLVLGHEITGEVIEKGRDVENLQIGDLVSVPFNVACGRCRSCKEMHTGVCLTVNPARAGGAYGYVDMGDWTGGQAEYLLVPYADFNLLKLPDRDKAMEKIRDLTCLSDILPTGYHGAVTAGVGPGSTVYVAGAGPVGLAAAASARLLGAAVVIVGDLNPARLAHAKAQGFEIADLSLDTPLHEQIAALLGEPEVDCAVDAVGFEARGHGHEGAKHEAPATVLNSLMQVTRVAGKIGIPGLYVTEDPGAVDAAAKIGSLSIRFGLGWAKSHSFHTGQTPVMKYNRALMQAIMWDRINIAEVVGVQVISLDDAPRGYGEFDAGVPKKFVIDPHKTFSAA'], 'length': tensor([399])}]\n",
      "[{'primaryAccession': ['P46415'], 'taxonId': tensor([7227]), 'value': ['MSATEGKVITCKAAVAWEAKKPLVIEDIEVAPPKAHEVRIKITATGVCHTDAFTLSGADPEGLFPVVLGHEGAGIVESVGEGVTNFKAGDHVIALYIPQCNECKFCKSGKTNLCQKIRLTQGAGVMPEGTSRLSCKGQQLFHFMGTSTFAEYTVVADISLTKINEKAPLEKVCLLGCGISTGYGAALNTAKVEAGSTCAVWGLGAVGLAVGLGCKKAGAGKIYGIDINPDKFELAKKFGFTDFVNPKDVADKGSIQNYLIDLTDGGFDYTFECIGNVNTMRSALEATHKGWGTSVVIGVAGAGQEISTRPFQLVVGRVWKGSAFGGWRSVSDVPKLVEDYLKKDLLVDEFITHELPLSQINEAFDLMHKGESIRSIIKY'], 'length': tensor([379])}]\n",
      "[{'primaryAccession': ['O13437'], 'taxonId': tensor([5477]), 'value': ['MKIVLVLYDAGKHAADEEKLYGCTENKLGIANWLKDQGHELITTSDKEGETSELDKHIPDADIIITTPFHPAYITKERLDKAKNLKLVVVAGVGSDHIDLDYINQTGKKISVLEVTGSNVVSVAEHVVMTMLVLVRNFVPAHEQIINHDWEVAAIAKDAYDIEGKTIATIGAGRIGYRVLERLLPFNPKELLYYDYQALPKEAEEKVGARRVENIEELVAQADIVTVNAPLHAGTKGLINKELLSKFKKGAWLVNTARGAICVAEDVAAALESGQLRGYGGDVWFPQPAPKDHPWRDMRNKYGAGNAMTPHYSGTTLDAQTRYAEGTKNILESFFTGKFDYRPQDIILLNGEYVTKAYGKHDKK'], 'length': tensor([364])}]\n",
      "[{'primaryAccession': ['P33160'], 'taxonId': tensor([33067]), 'value': ['MAKVLCVLYDDPVDGYPKTYARDDLPKIDHYPGGQTLPTPKAIDFTPGQLLGSVSGELGLRKYLESNGHTLVVTSDKDGPDSVFERELVDADVVISQPFWPAYLTPERIAKAKNLKLALTAGIGSDHVDLQSAIDRNVTVAEVTYCNSISVAEHVVMMILSLVRNYLPSHEWARKGGWNIADCVSHAYDLEAMHVGTVAAGRIGLAVLRRLAPFDVHLHYTDRHRLPESVEKELNLTWHATREDMYPVCDVVTLNCPLHPETEHMINDETLKLFKRGAYIVNTARGKLCDRDAVARALESGRLAGYAGDVWFPQPAPKDHPWRTMPYNGMTPHISGTTLTAQARYAAGTREILECFFEGRPIRDEYLIVQGGALAGTGAHSYSKGNATGGSEEAAKFKKAV'], 'length': tensor([401])}]\n",
      "[{'primaryAccession': ['G0SGU4'], 'taxonId': tensor([759272]), 'value': ['MVKVLAVLYDGGEHAKQVPGLLGTTENELGLRKWLEDQGHTLVTTSDKDREGSTFDRELEDAEIIITTPFHPGYLTAERLARAKKLKLAVTAGIGSDHVDLDAANKTNGGITVAEVTGSNVVSVAEHVVMTILVLVRNFVPAHEQIEAGRWDVAEVAKDEYDLEGKVVGTVGVGRIGERVLRRLKGFDCKELLYYDYQPLSPEKEKEIGCRRVENLEEMLAQCDVVTINCPLHESTRGLFNKDLISKMKRGSWLVNTARGAIVVKEDVAEALRTGHLRGYGGDVWFPQPAPADHVLRTAKNPFGGGNAMVPHMSGTSLDAQKRYAEGVKRILDSYLSGRFDYRPEDLIVHQGKYATRAYGQREDVKIPGQ'], 'length': tensor([370])}]\n",
      "[{'primaryAccession': ['Q9S7E4'], 'taxonId': tensor([3702]), 'value': ['MAMRQAAKATIRACSSSSSSGYFARRQFNASSGDSKKIVGVFYKANEYATKNPNFLGCVENALGIRDWLESQGHQYIVTDDKEGPDCELEKHIPDLHVLISTPFHPAYVTAERIKKAKNLKLLLTAGIGSDHIDLQAAAAAGLTVAEVTGSNVVSVAEDELMRILILMRNFVPGYNQVVKGEWNVAGIAYRAYDLEGKTIGTVGAGRIGKLLLQRLKPFGCNLLYHDRLQMAPELEKETGAKFVEDLNEMLPKCDVIVINMPLTEKTRGMFNKELIGKLKKGVLIVNNARGAIMERQAVVDAVESGHIGGYSGDVWDPQPAPKDHPWRYMPNQAMTPHTSGTTIDAQLRYAAGTKDMLERYFKGEDFPTENYIVKDGELAPQYR'], 'length': tensor([384])}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import json\n",
    "\n",
    "with open('../data/processed/uniref100_test.json', 'r') as file :\n",
    "    json_data = json.load(file)\n",
    "\n",
    "\n",
    "# jsondb = json_data['results']\n",
    "# jsondb[23]\n",
    "\n",
    "jsondb = pd.read_json(json.dumps(json_data))\n",
    "\n",
    "jsondb = get_taxon_sequence_data(jsondb)\n",
    "\n",
    "datasetjson = ProteinDataset(jsondb)\n",
    "sampler = TaxonIdSampler(batch_size= 5, dataset=datasetjson, shuffle= True)\n",
    "dataloader = DataLoader(dataset = datasetjson, sampler = sampler)\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proteusAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
