{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pymongo import MongoClient\n",
    "from functools import reduce\n",
    "from collections import defaultdict\n",
    "#import proteusAI as pai\n",
    "import os\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "import esm\n",
    "#For knowledge distillation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch.nn.functional as functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining esm_compute with smaller ESM-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esm2_compute(seqs: list, names: list=None, model: Union[str, torch.nn.Module]=\"student\", rep_layer: int=33, device=None):\n",
    "    \"\"\"\n",
    "    Compute the of esm_tools models for a list of sequences.\n",
    " \n",
    "    Args:\n",
    "        seqs (list): protein sequences either as str or biotite.sequence.ProteinSequence.\n",
    "        names (list, default None): list of names/labels for protein sequences.\n",
    "            If None sequences will be named seq1, seq2, ...\n",
    "        model (str, torch.nn.Module): choose either esm2, esm1v or a pretrained model object.\n",
    "        rep_layer (int): choose representation layer. Default 33.\n",
    "        device (str): Choose hardware for computation. Default 'None' for autoselection\n",
    "                          other options are 'cpu' and 'cuda'.\n",
    " \n",
    "    Returns: representations (list) of sequence representation, batch lens and batch labels\n",
    " \n",
    "    Example:\n",
    "        seqs = [\"AGAVCTGAKLI\", \"AGHRFLIKLKI\"]\n",
    "        results, batch_lens, batch_labels = esm_compute(seqs)\n",
    "    \"\"\"\n",
    "    # detect device\n",
    "    if device == None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    else:\n",
    "        device = torch.device(device)\n",
    " \n",
    "    # on M1 if mps available\n",
    "    #if device == torch.device(type='cpu'):\n",
    "    #    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    " \n",
    "    # load model\n",
    "    if isinstance(model, str):\n",
    "        if model == \"student\":\n",
    "            model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "        elif model == \"teacher\":\n",
    "            model, alphabet = esm.pretrained.esm2_t12_35M_UR50D()\n",
    "        else:\n",
    "            raise ValueError(f\"{model} is not a valid model\")\n",
    "    elif isinstance(model, torch.nn.Module):\n",
    "        alphabet = torch.load(os.path.join(Path(__file__).parent, \"alphabet.pt\"))\n",
    "    else:\n",
    "        raise TypeError(\"Model should be either a string or a torch.nn.Module object\")\n",
    " \n",
    " \n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    " \n",
    "    if names == None:\n",
    "        names = names = [f'seq{i}' for i in range(len(seqs))]\n",
    " \n",
    "    data = list(zip(names, seqs))\n",
    " \n",
    "    # check datatype of sequences - str or biotite\n",
    "    if all(isinstance(x[0], str) and isinstance(x[1], str) for x in data):\n",
    "        pass  # all elements are strings\n",
    "    else:\n",
    "        data = [(x[0], str(x[1])) for x in data]\n",
    " \n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "    batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    " \n",
    "    # Extract per-residue representations (on CPU)\n",
    "    with torch.no_grad():\n",
    "        results = model(batch_tokens.to(device), repr_layers=[rep_layer], return_contacts=True)\n",
    " \n",
    "    return results, batch_lens, batch_labels, alphabet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rest of the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taxon_sequence_data(collection):\n",
    "\n",
    "    # Define the query filter to exclude documents where sequence.length > 1024\n",
    "    query = {\n",
    "        \"sequence.length\": {\"$lte\": 1024}\n",
    "    }\n",
    "    projection = {\n",
    "    \"primaryAccession\": 1,    \n",
    "    \"organism.taxonId\": 1,   # Include taxonId from the organism field\n",
    "    \"sequence.value\": 1,      # Include value from the sequence field\n",
    "    \"sequence.length\": 1      # Include length from the sequence field\n",
    "    }\n",
    "    documents =  collection.find(query, projection)\n",
    "\n",
    "    minimal_documents = [] # Initialize new empty dictionary\n",
    "\n",
    "    for doc in documents:\n",
    "    # Create a new dictionary with only the desired properties\n",
    "        new_obj = {\n",
    "            \"primaryAccession\": doc.get(\"primaryAccession\",{}),\n",
    "            \"taxonId\": doc.get(\"organism\", {}).get(\"taxonId\"),\n",
    "            \"value\": doc.get(\"sequence\", {}).get(\"value\"),\n",
    "            \"length\": doc.get(\"sequence\", {}).get(\"length\")\n",
    "        }\n",
    "        minimal_documents.append(new_obj)\n",
    "\n",
    "\n",
    "    return minimal_documents\n",
    "\n",
    "def get_seq_rep(results, batch_lens, rep_layer = 33):\n",
    "    \"\"\"\n",
    "    Get sequence representations from esm_compute\n",
    "    \"\"\"\n",
    "    token_representations = results[\"representations\"][rep_layer]\n",
    " \n",
    "    # Generate per-sequence representations via averaging\n",
    "    sequence_representations = []\n",
    "    for i, tokens_len in enumerate(batch_lens):\n",
    "        sequence_representations.append(token_representations[i, 1: tokens_len - 1].mean(0))\n",
    " \n",
    "    return sequence_representations\n",
    " \n",
    " \n",
    "def get_logits(results):\n",
    "    \"\"\"\n",
    "    Get logits from esm_compute\n",
    "    \"\"\"\n",
    "    logits = results[\"logits\"]\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy test with student model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = [\"AGAVCTGAKLI\", \"AGHRFLIKLKI\"]\n",
    "results, batch_lens, batch_labels, alphabet = esm2_compute(seqs, rep_layer=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract representations and logits from results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "representations_student = get_seq_rep(results, batch_lens, rep_layer = 0)\n",
    "logits_student = get_logits(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, batch_lens, batch_labels, alphabet = esm2_compute(seqs, rep_layer=0, model = \"teacher\")\n",
    "representations_teacher = get_seq_rep(results, batch_lens, rep_layer = 0)\n",
    "logits_teacher = get_logits(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for addressing differences in dimensionality between kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_match(teacher_kernel, student_kernel):\n",
    "    \"\"\"\n",
    "    Just a precaution function. It assures that tokens embeddings in both teacher and student\n",
    "    representations have the same shape. This will apply zero-padding the kernel with less dimensions.\n",
    "    \"\"\"\n",
    "    rows = max(teacher_kernel.shape[0], student_kernel.shape[0])\n",
    "    cols = max(teacher_kernel.shape[1], student_kernel.shape[1])\n",
    "    new_teacher_kernel = functional.pad(teacher_kernel, (0, cols - teacher_kernel.shape[1], \n",
    "                                                            0, rows - teacher_kernel.shape[0]))\n",
    "    new_student_kernel = functional.pad(student_kernel, (0, cols - student_kernel.shape[1], \n",
    "                                                            0, rows - student_kernel.shape[0]))\n",
    "    return new_teacher_kernel, new_student_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distillation loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "def kernel_similarity_matrix(kernel):\n",
    "    \"\"\"\n",
    "    Calculates the cosine similarity between each pair of token embeddings on the kernel\n",
    "    \"\"\"\n",
    "    return cosine_similarity(kernel.cpu().detach().numpy())\n",
    "\n",
    "def kernel_mse_alignment_loss(teacher_kernel, student_kernel):\n",
    "    \"\"\"\n",
    "    Calculates the MSE kernel alignment loss between teacher and student\n",
    "    \"\"\"\n",
    "    teacher_matrix = torch.tensor(kernel_similarity_matrix(teacher_kernel))\n",
    "    student_matrix = torch.tensor(kernel_similarity_matrix(student_kernel))\n",
    "\n",
    "    if teacher_matrix.shape != student_matrix.shape:\n",
    "        teacher_matrix, student_matrix = pad_to_match(teacher_matrix, student_matrix)\n",
    "\n",
    "    return mse_loss(teacher_matrix, student_matrix)\n",
    "\n",
    "def logits_mse_loss(teacher_logits, student_logits):\n",
    "    \"\"\"\n",
    "    Calculates the MSE loss between teacher and student logits\n",
    "    \"\"\"\n",
    "    return mse_loss(teacher_logits, student_logits)\n",
    "\n",
    "def distillation_loss(teacher_rep, teacher_logits, student_rep, student_logits, weight_rep = 1, weight_logits = 1):\n",
    "    \"\"\"\n",
    "    Calculates the combined MSE loss between kernel alignment and logits\n",
    "    \"\"\"\n",
    "    alignment_loss = kernel_mse_alignment_loss(teacher_rep, student_rep)\n",
    "    logits_loss = logits_mse_loss(teacher_logits, student_logits)\n",
    "    return weight_rep * alignment_loss + weight_logits * logits_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing KD loss computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge distillation loss (dummy data): 0.6618165969848633\n"
     ]
    }
   ],
   "source": [
    "student_logits = logits_student\n",
    "teacher_logits = logits_teacher\n",
    "\n",
    "student_rep = torch.stack(representations_student)\n",
    "teacher_rep = torch.stack(representations_teacher)\n",
    "\n",
    "\n",
    "\n",
    "kd_loss = distillation_loss(teacher_rep, teacher_logits, student_rep, student_logits)\n",
    "\n",
    "print(\"Knowledge distillation loss (dummy data): {}\".format(kd_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_plm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
