LLM_Project/
│
├── data/                        # Directory for datasets
│   ├── raw/                     # Raw data files
│   ├── processed/               # Preprocessed data ready for training
│   └── scripts/                 # Scripts for data cleaning and preprocessing
│
├── src/                         # Main source code
│   ├── __init__.py
│   ├── models/                  # Model architectures
│   │   ├── __init__.py
│   │   └── llm_model.py         # LLM model classes (e.g., GPT-based models)
│   │
│   ├── utils/                   # Helper functions and utilities
│   │   ├── __init__.py
│   │   ├── data_utils.py        # Data loading, augmentation functions
│   │   └── model_utils.py       # Functions for model setup, parameter initialization
│   │
│   ├── training/                # Training-related code
│   │   ├── __init__.py
│   │   └── trainer.py           # Training loop and related functions
│   │
│   ├── evaluation/              # Evaluation and metrics
│   │   ├── __init__.py
│   │   └── metrics.py           # Code for evaluation metrics and validation
│   │
│   └── config/                  # Configuration files
│       └── config.yaml          # YAML file for hyperparameters, paths, etc.
│
├── tests/                       # Unit and integration tests
│   ├── test_data_utils.py       # Tests for data utilities
│   ├── test_model_utils.py      # Tests for model utilities
│   ├── test_training.py         # Tests for training functions
│   └── test_metrics.py          # Tests for evaluation metrics
│
├── notebooks/                   # Jupyter notebooks for exploratory data analysis, prototyping
│   ├── EDA.ipynb                # Initial exploratory data analysis
│   └── model_prototyping.ipynb  # Experimenting with models
│
├── experiments/                 # Directory for experiment tracking
│   ├── logs/                    # Logs for each experiment
│   └── checkpoints/             # Model checkpoints and weights
│
├── scripts/                     # Standalone scripts for running tasks
│   ├── train.py                 # Script to start training
│   └── evaluate.py              # Script for evaluation
│
├── .gitignore                   # Git ignore file
├── README.md                    # Project overview and instructions
└── requirements.txt             # List of dependencies

## Suggested commit system:

To have everything ordered while we work I propose adding commit tags so we can know what is happening.
the system proposed is the following:

	1.	feat: A new feature or functionality
	•	Example: feat(model): add transformer architecture
	2.	fix: A bug fix
	•	Example: fix(data): handle missing values in preprocessing
	3.	docs: Documentation updates (including README changes, code comments)
	•	Example: docs(training): add details on hyperparameter tuning
	4.	style: Code style updates (e.g., formatting changes, non-functional changes like indentation, renaming variables)
	•	Example: style(training): rename variables for clarity
	5.	refactor: Code restructuring without changing functionality
	•	Example: refactor(model): modularize layer definitions
	6.	test: Adding or updating tests
	•	Example: test(data): add unit tests for data augmentation
	7.	chore: Routine tasks, dependency updates, build scripts, etc.
	•	Example: chore(dependencies): update numpy to 1.23
        8.      init: Use this tag specifically for creating new files or setting up initial project files (e.g., setting up a new module or adding configuration files)•	Examples:
	•	init(data): add initial data preprocessing script
